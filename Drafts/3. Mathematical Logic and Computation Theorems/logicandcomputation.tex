\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{url}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{graphicx, adjustbox}
\usepackage{lmodern}
\usepackage{fourier}
\usepackage{float}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{mhchem}
\usepackage[left=1.5cm,right=1.5cm,top=1cm,bottom=3cm]{geometry}
\usepackage{multicol}
\usepackage{soul}



%Colors
\usepackage[dvipsnames]{xcolor}


\definecolor{black}{RGB}{0, 0, 0}
\definecolor{richblack}{RGB}{7, 14, 13}
\definecolor{charcoal}{RGB}{45, 67, 77}
\definecolor{delectricblue}{RGB}{93, 117, 131}
\definecolor{cultured}{RGB}{245, 245, 245}
\definecolor{lightgray}{RGB}{211, 216, 218}
\definecolor{silversand}{RGB}{190, 194, 198}
\definecolor{spanishgray}{RGB}{148, 150, 157}
\definecolor{darkliver}{RGB}{64, 63, 76}

\colorlet{lightdelectricblue}{delectricblue!30}
\colorlet{lightdarkliver}{darkliver!30}


%ColorDefines
\newcommand{\trueblack}[1]{\textcolor{black}{#1}}
\newcommand{\rich}[1]{\textcolor{richblack}{#1}}
\newcommand{\lightblack}[1]{\textcolor{charcoal}{#1}}
\newcommand{\lightrich}[1]{\textcolor{delectricblue}{#1}}


%Boxes
\usepackage{tcolorbox}
\newtcolorbox{calloutbox}{center,%
    colframe =red!0,%
    colback=cultured,
    title={Callout},
    coltitle=richblack,
    attach title to upper={\ ---\ },
    sharpish corners,
    enlarge by=0.5pt}

\newtcolorbox[use counter=equation]{eq}{center,
	colframe =red!0,
	colback=cultured,
	title={\thetcbcounter},
	coltitle=richblack,
	detach title,
	after upper={\par\hfill\tcbtitle},
	sharpish corners,
    enlarge by=0.5pt }
    
\newtcolorbox{qt}{center,
	colframe=delectricblue,
	colback=white!0,
	title={\large "},
	coltitle=delectricblue,
	attach title to upper,
	after upper ={\large "},
	sharp corners,
	enlarge by=0.5pt,
	boxrule=0pt,
	leftrule=2pt}
	
\newtcolorbox{exc}{center,%
    colframe =red!0,%
    colback=darkliver!15,
    title={Excercise},
    coltitle=richblack,
    attach title to upper={\ ---\ },
    sharpish corners,
    enlarge by=0.5pt}
    
\newcounter{theo}
\newtcolorbox[use counter=theo]{theorem}
	{center,%
    colframe =red!0,%
    colback=cultured,
    title={Theorem \thetcbcounter},
    coltitle=richblack,
    attach title to upper={\ ---\ },
    sharpish corners,
    enlarge by=0.5pt}

\newcounter{defcounting}
\newtcolorbox[use counter=defcounting]{define}
{center,%
	colframe=darkliver!50,%
	colback=white!0,
	title={\textcolor{black}{\textbf{\textit{Definition}} \  \thetcbcounter  \ --}},
	coltitle=darkliver!50,
	attach title to upper,
	after upper ={ },
	sharp corners,
	enlarge by=0.5pt,
	boxrule=0pt,
	leftrule=2pt,
    rightrule = 0pt}

\newcounter{lemmacount}
\newtcolorbox[use counter=lemmacount]{lemma}
{center,%
    colframe=charcoal!50,%
    colback=white!0,
    title={\textcolor{black}{\textbf{\textit{Lemma}} \  \thetcbcounter  \ --}},
    coltitle=darkliver!50,
    attach title to upper,
    after upper ={ },
    sharp corners,
    enlarge by=0.5pt,
    boxrule=2pt}
    

\newcounter{examplecounter}
\newtcolorbox[use counter=examplecounter]{example}
	{center,%
    colframe =red!0,%
    colback=cultured,
    title={Example},
    coltitle=richblack,
    attach title to upper={\ ---\ },
    sharpish corners,
    enlarge by=0.5pt}

    

        
    
% Highlighters
\newcommand{\hldl}[1]{%
	\sethlcolor{lightdarkliver}%
	\hl{#1}
}
\newcommand{\hldb}[1]{%
    \sethlcolor{lightdelectricblue}%
    \hl{#1}%
}


% Images
\newcounter{figurecounter}
\setcounter{figurecounter}{1}

\newcommand{\img}[3]{
    \begin{figure}[h!]
        \centering
        \captionsetup{justification=centering,margin=0cm,labelformat=empty}
        \includegraphics[width=#2\linewidth]{./img/#1}
        \label{figure}
        \caption{\small\textbf{fig-\thefigurecounter} -- \textcolor{darkliver}{#3}}
    \end{figure}
    \addtocounter{figurecounter}{1}}

\newcommand{\imgr}[3]{
    \begin{wrapfigure}{r}{#2\textwidth}
        \centering
        \captionsetup{justification=centering,margin=0cm,labelformat=empty}
        \includegraphics[width=\linewidth]{./img/#1}
        \label{figure}
        \caption{\small \textbf{fig: \thefigurecounter} -- \textcolor{darkliver}{#3}}
    \end{wrapfigure}
    \addtocounter{figurecounter}{1}}

\newcommand{\imgl}[3]{
    \begin{wrapfigure}{l}{#2\textwidth}
        \centering
        \captionsetup{justification=centering,margin=0cm,labelformat=empty}
        \includegraphics[width=\linewidth]{./img/#1}
        \label{figure}
        \caption{\small \textbf{fig: \thefigurecounter} -- \textcolor{darkliver}{#3}}
    \end{wrapfigure}
    \addtocounter{figurecounter}{1}}

% New commands
\newenvironment{callout}
	{\begin{calloutbox}\color{charcoal}\textbf\textit}
	{\end{calloutbox}}

% for this file
\newcommand{\newpoint}[1]{\indent$\mathsection$ \textbf{#1}}
\newcommand{\curveL}{\mathcal{L}}
\newcommand{\curveA}{\mathcal{A}}
\newcommand{\curveP}{\mathcal{P}}
\newcommand{\thm}{\text{Thm}}
\newcommand{\proof}{\\ \ \\ $\blacktriangleright$ \textit{proof: }}

\title{Mathematical Limits \\ \large Logic and Computational Theorems}
\author{Amir H. Ebrahimnezhad}
\date{\today}
\begin{document}
        \maketitle
        \tableofcontents
        \section{Ground Works}
            \subsection{Vorwort}
                GÃ¶del's incompleteness theorems, are two theorems of mathematical logic that deal with the limits of provability in formal axiomatic theories. The theorems are interpreted as showing that Hilber's program to find a complete and consistent set of axioms for all mathematics is impossible.
                \\
                \\
                In the following work we will first describe the theorem and preliminaries, and then prove it using algorithm theory methods and other methods. Then we are going to talk about it's consequences in pure mathematics and philosophy of mathematics, later we will discuss the relation between the theorems and the church-turing thesis We then would discuss related works that has pushed the theorem further and shown aspects of it. At the final section we will investigate a philosophical picture of Mathematical Universe and if it is acceptable to consider a bigger abstract world of mathematical objects where the real world is a subset of it. 
            \section{Formal Language Theory}
                The investigation of Incompleteness theorem requiers the knowledge of some basic ideas such as languages, grammars, automatas and others. Therefore we start this draft by talking about these topics in a general format. A more detailed version would be published later.\cite{Leary2019-ip}
                \subsection{Languages}
                    We would begin by the definition of a language. In a informal way a language is what we speak or what we write on a paper to give information to another person, mathematically and a more abstract idea of a language is a bunch of symbols that we have to make words (gluing symbols together to resemble a unity of them); To give a precise mathematical definition of language we would first define alphabet as:
                    \begin{define}
                        \textit{An alphabet $\Sigma$, is a set of symbols.}
                    \end{define}
                    \begin{define}
                        \textit{A word $M$, is a combination of symbols from alphabet $\Sigma$.}
                    \end{define}
                    For instance one could choose the set $\{a,b,c,d,\dots\}$ as ones alphabet. Then "$cat$" is a word in it's alphabet. As you can see there's a meaning for the word we gave as an example. It defines an object (more accurately a living creature). Since there can be Infinetly many words for any alphabet (other than an empty set which have no words), we distinguish between the accepted combinations and the ones we don't accept by defining a grammar for our language;  A grammar is a way to characterize a language, a way to list which stings of $\Sigma$ is acceptable. We could simply list strings or have a set of rules (or an algorithm) to say if a given combination is acceptable or not for a language. Thus we define a language as:
                    \begin{define}
                        \textit{Given an alphabet $\Sigma$, $\Sigma^\infty$ is the set of all possible words in the alphabet.}
                    \end{define}
                    \begin{define}
                        \textit{A subset $S$ of a set $X$ is decidable if and only if there exists a function that given $x\in X$ decides if $x\in S$ is true or false.}
                    \end{define}
                    \begin{define}
                        \textit{A Language $L$, is a subset of the alphabet $\Sigma^\infty$ ($L\subset \Sigma^\infty$) where there exists a function $\eta(\sigma\in\Sigma^\infty)$ called grammar that decides $L$.}
                    \end{define}
                    Formally, we define a grammar as:
                    \begin{define}
                        \textit{A Grammar is a set $\{V_T,V_N,S, R\}$ where $V_T$ is the set of terminal elements, $V_N$ is the set of non-terminal elements, $S$ is a memeber of $V_N$, and $R$ is a finite set of rules.}
                    \end{define}
                    We would use these definitions in the later sections of this draft. But for now let us give a formal definition of $R$ as well:
                    \begin{define}
                        \textit{$R$ is a finite set of ordered pairs from $\Sigma^\infty V_N \Sigma^\infty\times \Sigma^\infty$, where $\Sigma = V_T\cup V_N$.}
                    \end{define}
                    In later drafts we would get back to the Formal language theory in more depth and examine the properties of the setsof languages each grammar formalism can accomodate and the set of abstract machines that correspond to each type. But for now we would start with the things we need for proving the incompleteness theorems that is the goal of this draft.\cite{Leary2019-ip}
                    \\
                    \\
                    \newpoint{Induction:} Induction is a method of proving that a statemens $P(n)$ is true for every natural number $n$, that is, that the infinitely many cases, $P(0), P(1),\dots$ all hold. \cite{enwiki:1157726892}
                    \begin{qt}
                        Mathematical induction proves that we can climb as high as we like on a ladder, by proving that we can climb onto the bottom rung (the basis) and that from each rung we can climb up to the next one (the step).
                    \end{qt}
                    \begin{theorem}
                        For every natural number $n$,
                        \begin{equation}
                            1+2+\dots + n = \frac{n(n+1)}{2}
                        \end{equation}
                    \
                    \proof If $n=1$, the equality holds. For the inductive case, fix $k\geq 1$ and assume that:
                    \begin{equation}
                        1+2+\dots+k =\frac{k(k+1)}{2}
                    \end{equation}
                    Now adding $k+1$ to each side we have:
                    \begin{equation}
                        1+2+\dots+(k+1) = \frac{k(k+1)}{2}+(k+1)
                    \end{equation}
                    Since the right hand side simplifies to:
                    \begin{equation}
                        \frac{(k+1)((k+1) + 1)}{2}
                    \end{equation}
                    Finishing the inductive step and thus the proof. As you can see in the inductive step what we prove is that:
                    \begin{qt}
                        \textit{If the formula holds for $k$, then the formula holds for $k+1$.}
                    \end{qt}
                    \end{theorem}
                    Looking at this from a slightly different angle, what we have done is to construct a set of numbers with a certain property. If we let $S$ stand for the set of numbers for which our theorem holds, in out proof by induction we whow that the set $S$, is identical with the set of natural numbers, thus the theorem holds for every natural number $n$, as needed.
                    \\
                    \\
                    So what makes a proof by induction work is the fact that the natural numbers can be defined recursively, There is a base case, consisting of the smallest natural number, and there is a recursive case, showing how to construct bigger natural number from smaller ones.
                    \\
                    \\
                    \newpoint{Terms and Formulas:} As we mentioned earlier not all words of a set $\Sigma^\infty$ is meaningful. Since any combination of the alphabet is a word there has to be distinctions between what are meaningful words and what are not. We would consider two kinds of words as \textit{terms \& formulas} as follow:
                    \begin{define}
                        \textit{If $\curveL$ is a language, a \textbf{term of $\curveL$} is a nonempty finite string $t$ of symbols from $\curveL$ such that either:}
                        \begin{enumerate}
                            \item $t$ is a variable, or
                            \item $t$ is a constant symbol, or 
                            \item $t:\equiv ft_1t_2t_3\dots t_n$, where $f$ is an $n$-ary function symbol of $\curveL$ and each of the $t_i$ is a term of $\curveL$.
                        \end{enumerate}
                    \end{define}
                    \begin{define}
                        \textit{If $\curveL$ is a language, a formula of $\curveL$ is a nonempty finite string of $\phi$ of symbols from $\curveL$ such that either:}
                        \begin{enumerate}
                            \item $\phi :\equiv = t_1t_2,$ where $t_1, t_2$ are terms of $\curveL$, or 
                            \item $\phi :\equiv R t_1t_2\dots t_n$ where $R$ is an $n$-ary relation symbol of $\curveL$ and $t_1, t_2, \dots , t_n$ are all terms of $\curveL$, or 
                            \item $\phi :\equiv (\neg \alpha)$ where $\alpha$ is a formula of $\curveL$, or
                            \item $\phi:\equiv (\alpha\lor \beta)$, where $\alpha$ and $\beta$ are formulas of $\curveL$, or 
                            \item $\phi :\equiv (\forall v)(\alpha)$, where $v$ is a variable and $\alpha$ is a formula of $\curveL$
                        \end{enumerate}
                    \end{define}
                    Notice that the five clauses of the definition can be separated into two groups. The first two clauses, the atomic formulas, are explicitly defined. The last three clauses are the recursive case, showing how if $\alpha$ and $\beta$ are formulas, they can be used to build more complex formulas, such as $(\alpha\lor\beta)$ or $(\forall v)(\alpha)$.
                    Now since the collection of formulas is defined recursively, we can use an inductive style proof when we want to prove that something is true about every formula. The inductive proof will consist of two parts, a base cae and an inductive case. First we prove the statement for every atomic formula and then using the inductive method we prove it for recursive formulas from the atomic ones. \textit{This method is called induction on the complexity of the formula, or induction on the structure of the formula.}
                    \\
                    \\
                    \newpoint{A First-order Language:} Before getting to Sentences one should know a definition for a first-order language. A first-order language $\curveL$ is defined as an infinite collection of symbols, separated into the following categories:
                    \begin{itemize}
                        \item \textit{Parentheses:} $(,)$.
                        \item \textit{Connectives:} $\land, \lor, \neg$.
                        \item \textit{Quantifier:} $\forall, \exists$.
                        \item \textit{Variables:} one for each positive integer $n$ denoted: $v_n$ for $n$th number.
                        \item \textit{Equality:} $=$.
                        \item \textit{Constant:} We can have a new symbol for each positive number or any other method that we distinguish between two numbert (we can use | for 1, || for 2 etc)
                        \item \textit{Functions:} For each positive integer $n$, some set of zero or more $n$-ary function symbols.
                        \item \textit{Relation:} For each positive integer $n$, some set of zero or more $n$-ary relation symbols.
                    \end{itemize}
                    \begin{callout}
                        Having $n$ arity means that it is intended to represent a function of $n$ variables.
                    \end{callout}
                    Notice that by defining such language one can avoid the process of finiding an algorithm of grammar (the one that differenciates between nonesense and meaningful words) since we defined all the possible functions and etc. This way we have to only

                    \newpoint{Sentences:} Among the formulas in the language $\curveL$, there are some in which we will be especially interested. These are the sentences of $\curveL$. The formulas that can be either true or false in a given mathematical model.\cite{Leary2019-ip}
                    \begin{define}
                        \textit{A sentence in a language $\curveL$ is a formula of $\curveL$ that contains no free variable.}
                    \end{define}
                    \newpoint{Structures: } Defining any language and with constansts, functions and etc. There can exist multiple ways to define structures as opposed to another. The point is that there is no preference. Thus without determining the structure under consideration, without deciding how we wishs to interpret the symbols of the language, we have no way of talking about the truth or falsity of a sentence. Thus we have:
                    \begin{define}
                        \textit{Fix a language $\curveL$. An $\curveL$-Structure $\curveA$ is a nonempty set $A$m caled the \textbf{Universe of $\curveA$}, together with:}
                        \begin{enumerate}
                            \item \textit{For each constant symbol $c$ of $\curveL$, an element $c^\curveA$ of $A$}
                            \item \textit{For each $n$-ary function symbol $f$ of $\curveL$, a function $f^\curveA L A^n\rightarrow A$, and }
                            \item \textit{For each $n$-ary relation symbol $R$ of $\curveL$, and $n$-ary relation $R^\curveA$ on $A$.}
                        \end{enumerate}
                    \end{define}
                    \newpoint{Truth in a Structure:} Now that we know some formal rules about what constitutes a language, we would like to merge syntax and semantics. We want to answer what is means to say that an $\curveL$-formula is true in an $\curveL$-structure $\curveA$.
                    \\
                    \\
                    To begin the process of tying together the symbols with the structures, we will introduce assignment functions. These assignment functions will formalize what it means to interpret a term or a formula in a structure.
                    \begin{define}
                        \textit{if $\curveA$ us an $\curveL$-structure, a \textbf{variable assignment function into $\curveA$} is a function $s$ that assigns to each variable an element of the universe $A$. So a variable assignment function into $\curveA$ is any function with domain $V$ and codomain $A$.}
                    \end{define}
                    We will have occasion to want to fix the value of the assignment function $s$ for certain variables, then:
                    \begin{define}
                        \textit{If $s$ is a variable assignment function into $\curveA$ and $x$ is a variable and $a\in A$, then $s[x|a]$ is the variable assignment function into $\curveA$ defined as follows:}
                        \begin{equation}
                            s[x|a](v) = \left\{
                                \begin{matrix}
                                    s(v) & \text{if} \ v \ \text{is a variable other than }x\\
                                    a & \text{if} \ v \ \text{is the variable} x 
                                \end{matrix}\right.
                        \end{equation}
                    \end{define} 
                    We call the function $s[x|a]$ and $x$-modification of the assignment function $s$. This is essentially the same function, except that the variable $x$ is now assigned to a particular element of the universe.
                    \\
                    \\
                    What we will do next is extend a variable assignment function to a term assignment function $\bar s$. Thius function will assign an element of the universe to each term of the language $\curveL$.
                    \begin{define}
                        \textit{Suppose that $\curveA$ is an $\curveL$-structure and $s$ is a variable assignment function into $\curveA$. The function $\bar s$ is called the term assignment function generated by $s$, is the function with domain consisting of the set of 
                        $\curveL$-terms and codomain $A$ defined recursively as follows:}
                        \begin{enumerate}
                            \item \textit{If $t$ is a variable, $\bar s(t) = s(t)$}.
                            \item \textit{If $t$ is a constant symbol $c$, then $\bar s(t)= c^\curveA$}.
                            \item \textit{If $t:\equiv ft_1t_2\dots t_n$, then $\bar s(t) = f^\curveA (\bar s(t_1),\bar s(t_2),\dots,\bar s(t_n))$}.
                        \end{enumerate}
                    \end{define}
                    Although we will be primarily interested in truth of sentences, we will
                    first describe truth (or satisfaction) for arbitrary formulas, relative to an
                    assignment function.
                    \begin{define}
                        \textit{Suppose that $\curveA$ us an $\curveL$-structure, $\phi$ is an $\curveL$-formula, and $s$: $V\rightarrow A$ is an assignment function. We will say that $\curveA$ satisfies $\phi$ with assignment $s$, and write $\curveA\vDash \phi[s]$, in the following circumstances:}
                        \begin{enumerate}
                            \item \textit{If $\phi :\equiv =t_1t_2$ and $\bar s(t_1)$ is the same element of the universe $A$ as $\bar s(t_2)$, or}
                            \item \textit{If $\phi :\equiv Rt_1\dots t_n$ and $(\bar s(t_1),\dots,\bar s(t_n))\in R^\curveA$, or}
                            \item \textit{If $\phi:\equiv (\neg \alpha)$ and $\curveA \not\vDash \alpha[s]$ (where $\not\vdash$ means "does not satisfy") or}
                            \item \textit{If $\phi:\equiv (\alpha\lor\beta)$ and $\curveA\vDash\alpha[s]$, or $\curveA \vDash\beta[s]$ (or both), or}
                            \item \textit{$\phi:\equiv(\forall x)(\alpha)$ and, for each element $a$ of $A$, $\curveA\vDash \alpha[s(x|a)]$}
                        \end{enumerate}
                    \end{define}
                    \begin{callout}
                        If $\Gamma$ is a set of $\curveL$-formulas, we say that $\curveA$ satisfies $\Gamma$ with assignment $s$, and write $\curveA\vDash \Gamma[s]$ if for each $\gamma\in\Gamma, \curveA\vDash \gamma[s]$
                    \end{callout}
                    \newpoint{Substitutions and Substitutability:} Suppose that you knew the sentence $\forall x \phi(x)$ was tru in particular structure $\curveA$. Then, if $c$ is a constant symbol in the language, you would certainly expect $\phi(c)$ to be true in $\curveA$ as well.
                    \\
                    \\
                    Suppose now that $\curveA\vDash \forall x\exists y\neg(x=y)$. This sentence is, in fact, true in any structure $\curveA$ such that $A$ has atleast two elements. The rules of substitutability that we will discuss in this section are designed to help us avoid this problem, the problem of attempting to substitute a term inside a quantifier that binds a variable involved in the term.
                    \begin{define}
                        \textit{Suppose that $u$ is a term, $x$ is a variable, and $t$ is a term. We define the term $u_t^x$, and read $u$ with $x$ replaced by $t$ as:}
                        \begin{enumerate}
                            \item \textit{If $u$ is a variable not equal to x, then $u_t^x$ is $u$}
                            \item \textit{If $u$ is $x$, then $u_t^x$ is $t$}
                            \item \textit{If $u$ is a constant symbol then $u_t^x$ is $u$}
                            \item \textit{If $u:\equiv fu_1u_2\dots u_n$, where $f$ is a $n$-ary function symbol and the $u_i$ are terms, then:}
                            \begin{equation}
                                u_t^x \ \text{is} \ f(u_1)_t^x\dots(u_n)_t^x
                            \end{equation}
                        \end{enumerate}
                    \end{define}
                    Having defined what it means to substitute a term for a variable now we define what is substitutability:
                    \begin{define}
                        \textit{Suppose that $\phi$ is a $\curveL$-formula, $t$ is a term, and $x$ is a variable. We say that $t$ is substitutable for $x$ in $\phi$ if:}
                        \begin{enumerate}
                            \item \textit{$\phi$ is atomic, or}
                            \item \textit{$\phi :\equiv \neg(\alpha)$ and $t$ is substitutable for $x$ in $\alpha$, or}
                            \item \textit{$\phi:\equiv (\alpha\lor\beta)$ and $t$ is substitutable for $x$ in both $\alpha$ and $\beta$}
                            \item \textit{$\phi:\equiv (\forall y)(\alpha)$ and either}
                            \begin{enumerate}
                                \item \textit{$x$ is not free in $\phi$, or}
                                \item \textit{$y$ does not occur in $t$ and$t$ is substitable or $x$ in $\alpha$.}
                            \end{enumerate}
                        \end{enumerate}
                    \end{define}
                    \newpoint{Logical Implication: } In this section we formalize the question that If I know this statement is true, is it necessarily the case that this other statement is true.
                    \begin{define}
                        \textit{Suppose that $\Delta$ and $\Gamma$ are sets of $\curveL$-formulas. We will say that $\Delta$ logically implies $\Gamma$ and write $\Delta\vDash \Gamma$ if for every $\curveL$-structure $\curveA$, if $\curveA\vDash\Delta$, then $\curveA\vDash\Gamma$.}
                    \end{define}
                    This definition says that if $\Delta$ is true in $\curveA$, then $\Gamma$ is true in $\curveA$. Remember, for $\Delta$ to be true in $\curveA$, it must be the case that $\curveA\vDash\Delta[s]$ for every assignment function $s$.
                    \begin{define}
                        An $\curveL$-formula $\phi$ is said to be valid if $\emptyset\vDash\phi$, in other words, if $\phi$ is true in every $\curveL$-structure with every assignment function $s$. In this case we will write $\vDash\phi$.
                    \end{define}
                    \begin{callout}
                        For the double turnstyle symbol $\vDash$, if there is a structure on the left, $\curveA\vDash \sigma$, we are discussing truth in a single structure. On the other hand if there is a set of sentences on the left $\Gamma\vDash\sigma$, then we are discussing logical implication.
                    \end{callout}
                \subsection{Deductions}
                    In this section we will try to formalize what is known to be the deductive method. In mathematics we generally tend to insist upon the existence of a proof for any true statement (or at least we hope so). A proof is a sequence of statements, each one of which can be justified by referring to previous statements. This is a perfectly reasonable starting point, and it brings us to the main difficuly we will have to address as we move from an informal understanding of what constitutes a proof to a formal definition of deduction.
                    \\
                    \\
                    The proofs that you have seen in your mathematical career have had a couple of nice properties. The first of these is that proofs are easy to follow. This doesn't mean that it is easy to discover a proof, but rather that if someone is showing you a proof, it should be easy to follow the steps of the proof and to understand why the proof is correct. The second admirable property of proofs is that when you prove something, you know that it is true! Our definition of deduction will be designed to make sure that deductions, too, will be easily checkable and will preserve truth.
                    \\
                    \\
                    We then would impose the following restrictions on our logical axioms and rules of inference:
                    \begin{enumerate}
                        \item There will be an algorithm that will decide, given a formula, whether or not that formula is a logical axiom.
                        \item There will be an algorithm that will decide, given a finite set of formulas $\Gamma$ and a fimula $\theta$, whether or not $(\Gamma,\theta)$ is a rule of inference.
                        \item For each rule of inference $(\Gamma,\theta)$, $\Gamma$ will be a finite set of formulas.
                        \item Each logical axiom will be valid.
                        \item Our rules of inference will preserve truth. In other words, for each rule of inference $(\Gamma, \theta)\rightarrow \Gamma\vDash\theta$.
                    \end{enumerate}
                    The idea is that there should be no brilliance and no insight required to check whether an alleged deduction of $\alpha$ is, infact, a deduction of $\alpha$. To check whether a deduction is correct will be such a simple procedure that it could be programmed into a computer.
                    \\
                    \\
                    We begin by fixing a language $\curveL$. Also assume that we have been given a fixed set of $\curveL$-formulas, $\Lambda$, is called the set of logical axioms, and a set of ordered pairs $(\Gamma, \phi)$, called the rules of inference. A deduction is going to be a finite sequence or ordered list, of $\curveL$-formulas with certain properties.
                    \begin{define}
                        \textit{Suppose that $\Sigma$ is a collection of $\curveL$-formulas and $D$ is a finite sequence $(\phi_1, \dots, \phi_n)$ of $\curveL$-formulas. We will say that $D$ is a deduction form $\Sigma$ if for each element in $D$:}
                        \begin{enumerate}
                            \item $\phi_i\in\Lambda$ ($\phi_i$ is a logical axiom), or
                            \item $\phi_i\in\Sigma$ ($\phi_i$ is a nonlogical axiom), or
                            \item There is a rule of inference $(\Gamma,\phi_i)$ such that $\Gamma\subseteq\{\phi_1,\dots,\phi_{i-1}\}$
                        \end{enumerate}
                    \end{define}
                        If there is a deduction form $\Sigma$, the last line of which is the formula $\phi$, we will call this a deduction form $\Sigma$ of $\phi$. And write: $\Sigma\vdash\phi$.
                        \begin{callout}
                            Well, we have now established what we mean by the word justified. In a deduction we are allowed to write down any $\curveL$-formula that we like, as long as that formula is either a logical axiom or is listed explicitly in a collection $\Sigma$ of nonlogical axioms. Any formula that we write in a deduction that is not an axiom must arise from previous formulas in the deduction via a rule of inference.
                        \end{callout}
                        \subsubsection{Logical Axioms} 
                            In this section we will gather together a collection of $\Lambda$ of logical axioms for $\curveL$. This set of axioms, though infinite, will be decidable. Which means that there exists an algorithm, which given an input $x$, can tell if $x\in\Lambda$ is true or false.
                            \\
                            \\
                            \newpoint{Equality Axioms:} We have taken the route of assuming that the equality symbol, $=$, is a part of the language iteself. There are three groups of axioms that are designed for this symbol. The first just says that any object is equal to itself:
                            \begin{equation}
                                x = x
                            \end{equation}
                            For the second group of axioms, assume that $x_i$ and $y_i$ are variables, and $f$ is an $n$-ary frunction symbol.
                            \begin{equation}
                                \left[(x_1 = y_1)\land (x_2 = y_2) \land\dots\land(x_n = y_n) \right] \rightarrow \left(f(x_1,x_2,\dots,x_n) = f(y_1,y_2,\dots,y_n)\right)
                            \end{equation}
                            The assumption for the third group of axioms is the same as for the second group, except that $R$ is assumed to be an $n$-ary relation symbol.
                            \begin{equation}
                                \left[(x_1 = y_1)\land (x_2 = y_2) \land\dots\land(x_n = y_n) \right] \rightarrow \left(R(x_1,x_2,\dots,x_n) = R(y_1,y_2,\dots,y_n)\right)
                            \end{equation}
                            \newpoint{Quantifier Axioms:} The quantifier axioms are designed to allow a very reasonable sort of entry in a deduction. Suppose that we know $\forall xP(x)$. Then, if $t$ is any term of the language, we should be able to state that $P(t)$ . To avoid some problems we will demand that the term $t$ be substitutable for the variable $x$.
                            \begin{align}
                                (\forall x\phi)\rightarrow \phi_t^x, \text{if } t \text{ is substitutable for } x \text{ in } \ \phi \\
                                \phi_t^x\rightarrow (\exists x\phi), \text{if } t \text{ is substitutable for } x \text{ in } \ \phi
                            \end{align}
                            In many logic texts, the first axiom would be called universal instantiation, while the second would be known as existential generalization. 
                        \subsubsection{Rules of Inference:}
                            There will be two types of Rules of Inference, one dealing with propositional consequence and one dealing with quantifier.
                            \\
                            \\
                            \newpoint{Propositional Consequence:}We work with a restricted language $curveP$, consisting only of a set of propositional variables $A,B,C,\dots$ and the connectives $\lor$ and $\neg$ . Notice there are no quantifiers, no relation symbols, no function symbols, and no constansts. Each propositional variable can be assigned one of two truth values, T,F for truth and falsity respectively. The we can define a function $v$ to assign the truth value and for extending that we would define:
                            \begin{equation}
                                \bar v(\phi) = \left\{
                                \begin{matrix}
                                    v(\phi) &\text{if } \phi \text{ is a propositional variable}
                                    \\
                                    F & \text{if } \phi:\equiv(\neg\alpha) \text{ and } \bar v{\alpha} = T
                                    \\
                                    F & \text{if } \phi:\equiv(\alpha\lor\beta) \text{and } \bar v(\alpha) = \bar (\beta) = F
                                    \\
                                    T & \text{otherwise}
                                \end{matrix}
                                \right.
                            \end{equation}
                            To discuss propositional consequence in first-order logic, we will transfer our formulas to the real of propositional logic and use the idea of tautology in that area. To be specific, given $\beta$ , an $\curveL$-formula of first-order logic, gere is a procedure that will convert $\beta$ to a formula $\beta_P$ of propositional logic corresponding to $\beta$:
                            \begin{enumerate}
                                \item Find all subfomulas of $\beta$ of the form $\forall x\alpha$ that are not in the scope of another quantifier. Replace them with propositional variables in a systematic fashion. This means that if $\forall yQ(y,c)$ appears twice in $\beta$ it is replaced by the same letter both times, and distinct subformulas are replaced with distict letters.
                                \item Find all aromic formulas that remain, and replace them systemically with new propositional variables.
                                \item At this point, $\beta$ will have been replaced with a propositional formula $\beta_P$
                            \end{enumerate}
                            We are now almost at a point where we can state out propositional rule of inference. Recall that a rule of inference is an ordered pair $(\Gamma,\phi)$, where $\Gamma$ is a set of $\curveL$-formulas and $\phi$ is a $\curveL$-formula.
                            \begin{define}
                                \textit{Suppose that $\Gamma_P$ is a set of propositional formulas and $\phi_P$ is a propositional formula. We will say that $\phi_P$ is a propositional consequence of $\Gamma_P$ if every truth assignment that makes each propositional formula in $\Gamma_P$ true also makes $\phi_P$ true. Notice that $\phi_P$ is a tautology if and only if $\phi_P$ is a propositional consequence of $\emptyset$.}
                            \end{define}
                            Notice that if $\Gamma_P=\{\gamma_{1P},\dots,\gamma_{nP}\}$ is a nonempty finite set of propositional formulas and $\phi_P$ is a propositional formula, then $\phi_P$ is a propositional consequence of $\Gamma_P$ if and only if:
                            \begin{equation}
                                \left[
                                    \gamma_{1P}\land\dots\land \gamma_{nP} 
                                \right]\rightarrow \phi_P 
                            \end{equation}
                            is a tautology.
                            \begin{callout}
                                A tautology is a formula of assertion that is true in every possible structure $\curveA$.
                            \end{callout}
                            Now we extend our definition:
                            \begin{define}
                                Suppose that $\Gamma$ is a finite set of $\curveL$-formulas and $\phi$ is an $\curveL$-formula. We will say that $\phi$ is a propositional consequence of $\Gamma$ if $\phi_P$ is a propositional consequence of $\Gamma_P$, where the two latter are the results of applying the procedure of making a first order logic formulas into propositional formulas.
                            \end{define}
                            \begin{define}
                                If $\Gamma$ is a finite set of $\curveL$-formulas, $\phi$ is an $\curveL$-formula, and $\phi$ is a propositional consequence of $\Gamma$ then $(\Gamma,\phi)$ is a rule of inference of type (PC).
                            \end{define}
                            \newpoint{Quantifier Rules} Suppose, without making any particular assumptions about $x$, that you were able to prove $x$ is $a$ then you also have proved $(\forall x)x$ is $a$. Looking at it from back to front we would have:
                            \begin{define}
                                Suppose that the variable $x$ is not free in the formula $\psi$. Then both of the following are rules of inference of type (QR).
                                \begin{align}
                                    \left(\left\{
                                        \psi\rightarrow\phi
                                    \right\}, \psi \rightarrow (\forall x \phi)\right)\\
                                    \left(\left\{
                                        \phi\rightarrow\psi
                                    \right\}, \exists x\phi \rightarrow \psi\right)
                                \end{align}
                            \end{define}
                \subsection{Soundness}
                    Generally in mathematics we would like to be sure that when something has been proved, then it is for sure, true. In thi section we will prove a theorem that shows that the logical system that we have developed has this highly desirable property. This result is called the Soundness Theorem. As you might recall the requirements that we set for our rule of inference are:
                    \begin{enumerate}
                        \item There will be an algorithm that will decide, given a formula $\theta$, whether or not $\theta$ is a logical axiom.
                        \item There will be an algorithm that will decide, given a finite set of formulas $\Gamma$ and a formula $\theta$, whether or not $(\Gamma, \theta)$ is a rule of inference.
                        \item For each rule of inference $(\Gamma,\theta)$, $\Gamma$ will be a finite set of formulas.
                        \item Each logical axiom will be valid.
                        \item Our rules of inference will preserve truth, or in other words, for each rule of inference $(\Gamma,\theta)$, $\Gamma\vDash \theta$.
                    \end{enumerate}
                    These requirements serve two purposes: They allow us to verify mechanically that an alleged deduction is in fact a deduction, and they provide the basis of the Soundness Theorem. The idea behind the Soundness theorem is very simple. Suppose that $\Sigma$ is a set of $\curveL$-formulas and suppose that there is a deduction of $\phi$ from $\Sigma$. What the Soundness Theorem tells us is that in any structure $\curveA$ that makes all of the formulas of $\Sigma$ true, $\phi$ is true as well.
                    \begin{theorem}
                        If $\Sigma\vdash\phi$, then $\Sigma\vDash\phi$
                        \\
                        \\
                        \textit{proof.} Let $\thm_\Sigma = \{\phi | \Sigma \vdash\phi\}$ and $C =\{\phi | \Sigma \vDash \phi\}$. By showing that $\thm\subseteq C$ we prove the theorem. Notice that $C$ has the following characteristics:
                        \begin{enumerate}
                            \item $\Sigma \subseteq C$. If $\sigma\in\Sigma$ then certainly $\Sigma\vDash\sigma$.
                            \item $\Lambda\subseteq C$. As the logical axioms are valid, they are true in any structure. Thus $\Sigma\vDash\lambda$ for any logical axiom.
                            \item If $(\Gamma,\theta)$ is a rule of inference and $\Gamma\subseteq C$, then $\theta\in C$. Then because: $\curveA\vDash\Gamma$ and $\Gamma\vDash\theta$ we know that $\curveA\vDash\theta$.
                        \end{enumerate}
                        Since we have the following proposition and $C$ has these characteritics the prove is completed:
                        \textit{Fix sets of $\curveL$-formulas $\Sigma$ and $\Lambda$ and a collection of rules of inference. The set $\thm_\Sigma$ is the smallest set $C$ such:}
                        \begin{itemize}
                            \item $\Sigma\subseteq C$
                            \item $\Lambda\subseteq C$ 
                            \item If $(\Gamma,\theta)$ is a rule of inference and $\Gamma\subseteq C$, then $\theta\in C$.
                        \end{itemize}
                    \end{theorem}
            \section{Completeness}
                Before beginning with the incompleteness theorem it might help to know actually what is completeness. We have established a deductive system consisting of logical axioms and rules of inference. The Soundness Theorem showed that our deductive system preserves truth; that is, if there is a deduction of a formula $\varphi$ from a set of formulas $\Sigma$, then $\varphi$ is true in any model of $\Sigma$. Formally, we write this as follows:
                $$\Sigma \vdash \varphi \implies \Sigma \models \varphi$$
                where $\vdash$ denotes provability in the deductive system, and $\models$ denotes semantic entailment.
                
                The Completeness Theorem is the first major result of this chapter, and it gives us the converse to the Soundness Theorem. Specifically, it states that every semantically valid formula is provable in our deductive system. In other words, if a formula is true in every model, then it can be proved using only the logical axioms and rules of inference we have established. Formally, we write this as follows:

                \begin{equation} 
                    \Sigma \models \varphi \implies \Sigma \vdash \varphi
                \end{equation}
                
                Combined with the Soundness Theorem, the Completeness Theorem gives us the following equivalence:
                
                \begin{define}
                    A deductive system consisting of a collection of logical axioms $\Lambda$ and a collection of rules of inference is said to be complete if for every set of nonlogical axioms $\Sigma$ and every $\curveL$-formula $\phi$,
                    \begin{equation}
                        \text{If } \Sigma\vDash\phi \text{, then } \Sigma\vdash\phi
                    \end{equation}
                \end{define}

                This equivalence assures us that if our deductive system allows us to prove a statement, then that statement is true, and conversely, if a statement is true in every model, then it can be proved using our deductive system.
                
                However, it is important to note that the Completeness Theorem only applies to formulas that are true in every possible model. It does not necessarily extend to formulas that are true in some but not all models. Furthermore, the theorem applies specifically to first-order logic and may not hold for other logical systems.
            \section{Incompleteness Theorems}
                \subsection{Mathematics}
                    \subsubsection{Prespective}
                        In the last section we talked about the completeness theorem, which investigated the fact that our deductive system is sound and complete. For the collection of lpgical axioms that we have set out, any formula $\phi$ that can be deduced from a set of nonlogical axioms $\Sigma$ will be true in all models of $\Sigma$ under any variable assignment function (soundness), and furthermore any formula $\phi$ that is true in all models of $\Sigma$ under every assignment functionwill be deducible from $\Sigma$ (completeness)--This means that we can prove every true statement within the system. Thus our deductive system is the best it can be.\cite{Hajek2007-fq}
                        \\
                        \\
                        Now in this section we would try to show how would Incompleteness be proved, since we have shown that th efirst order logic is sound and complete it is trvial to infere that Incompleteness and Completeness are to be proved for different languages, and wether or not we can use them in Physics is to be worked out separately. But in the last sections we surely developed necessary concepts for one, who would like to talk about completeness (or incompleteness) of a physical theory.
                        \\
                        \\
                        Later on we would dicuss why in uor view. This might be the case.
                    \subsubsection{Basic Proof from the Theory of Algorithm\cite{Uspensky1995-sm}}
                        We assume that we are given a subset $T$ of language $L$, which is called the set of \textit{true statements}. This set should contain only the statements in the language that would evaluate as True. In the process of assuming such subset we ommit the part where we would consider the statemens true or false. A language then would be completely defined (for our purpose) if we are given the \textit{fundamental pair:}
                        \begin{define}
                            \textit{Given a language $L$ and the subset of true statements $T$, we call $\left<L,T\right>$ a fundamental pair.}
                        \end{define}
                        \begin{define}
                            \textit{\textbf{Unprovable} means not provable, and provable means there exist a proof for such statement.}
                        \end{define}
                        Also the concept of proof, deduction, and induction were defined in previous sections. For the sake of simplicity consider a deductive system that consists of an alphabet called \textit{Alphabet of Proofs}, and denoted $P$. Then we would generally have $P^\infty$ as all the words that alphabet can have, but restrictions by grammar, rules of inference, induction, deduction etc, would provide us with a set of proofs called $\bar P$. As you would recall our deductive system would prove a statement, and only one for each proof. Therefore given a language $\curveL_x$ and a proof language $P$ one would require the existence of an algorithm that can map a proof from $P$ to a true statement from $\curveL_x$. Therefore a deductive system (in the most simple manner, but you can still consider the deduction introduced in the previous sections.) would be made of $P$, $\bar P$, $\delta$, where $\delta$ is a function that maps proofs from $P$ to true statements from $\curveL_x$.
                        \begin{define}
                            \textit{We would call $\left<P,\bar P, \delta\right> a deductive system.$}
                        \end{define}
                        So our final definition is as follows:
                        \begin{enumerate}
                            \item We have a language $\curveL$ and an alphabet $P$ for the proofs. 
                            \item In the set $P^\infty$ we are given a subset $\bar P$, whose elements are called proofs. We futher assume:
                            \begin{enumerate}
                                \item We shall allow different concepts of proofs, different proof subsets of $P^\infty$. We shall also allow the alphabet $P$ to vary.
                                \item There has to be an effective method or algorithm to check if a given word in $P$ is a proof and to show what stetement it proves.
                            \end{enumerate}
                            \item We have a function $\delta$ (to determine what is being proved) whose domain of definition $\Delta$ satisfies $\bar P\subseteq \Delta\subseteq P^\infty$, and whose range of valurs is in $L^\infty$. We assue that we have an algorithm which computes this function. Therefore we might say that the proof $p$ in $\bar P$ is the proof of $\delta(p)$ in the language $\curveL$.
                        \end{enumerate}
                        Therefore we can now define consistency and completeness more easily:
                        \begin{define}
                            \textit{We say the deductive system $\left<P,\bar P, \delta\right>$ is consistent relative to the fundamental pair $\left<\curveL,T\right>$ if we have $\delta(\bar P) \subseteq T$. In other words our deductive system would not prove contradictory statements.}
                        \end{define}
                        \begin{define}
                            \textit{We say the deductive system $\left<P,\bar P, \delta\right>$ is complete relative to the fundamental pair $\left<\curveL,T\right>$ if we have $T \subseteq \delta(\bar P)$. In other words our deductive system would prove every true statements within the language.}
                        \end{define}
                        Conditions for the nonexistence of a complete and consistent deductive system can easily be given in terms of the theory of algorithms. An algorithm is a set of instructions which, given an input enables us to obtain an output if such an output exists or else obtain nothing at all if theres no output for out particular input. For our purpose consider that every input and output is a word thus there exists alphabet $I$ for inputs and alphabet $O$ for outputs.
                        \\
                        \\
                        In other words, in order to work with algorithms which process paris or sequences of words we must first compress such pairs or sequences of as single words in the algorithm, in a new alphabet.
                        \\
                        \\
                        Let $\star$ denote for a new letter not in our alphabet $\curveL$. Thus $\curveL_\star$ is a new alphabet. We would use such letter to denote separation between words in our alphabet.
                        \\
                        \\
                        Now we must define some terms:
                        \begin{define}
                            \textit{\textbf{Domain of Applicability:} The set of all inputa that can be processes by a given algorithm is called the domain of applicability of the algorithm.}
                        \end{define}
                        \begin{define}
                            \textit{The algorithm $A$ computes the function $f$, if we have $A(x)\sim f(x)$ for all $x$}
                        \end{define}
                        \begin{callout}
                            Note that $\sim$ is the conditional equality sign, both sides are equal when they are defined and bot sides are undefined under same $x$.
                        \end{callout}
                        \begin{define}
                            \textit{A function that can be computed by some algorithm is called a computable function.}
                        \end{define}
                        \begin{define}
                            \textit{\textbf{Decidable:} A subset $S$ of a set $A$ is said to be decidable if there exsits and algorithm which determines whether or not an element of $A$ is in $S$.}
                        \end{define}
                        We would require the set of all proofs be decidable set of all the words in proof alphabet. 
                        \begin{lemma}
                            For any subset $X$, the set $\emptyset$ and $X$ are decidable relative to $X$.
                            \proof We provide an algorithm for the subset $X$ of $X$ that always returnes true. And for the $\emptyset$ always false.
                        \end{lemma}
                        \begin{theorem}
                            If $T$ is an enumerable set, then one can find a complete and consistent deductive system for the fundamental pair $\left<\curveL, T\right>$
                            \proof if $T=\emptyset$ the deductive system $\left<P, \bar P, \delta\right>$ where $\bar P = \emptyset$ and $delta(p)=\emptyset$ is consistent and complete relative to $T$.
                            \\
                            Otherwise if $T \not = \emptyset$ since it is enumerable (there exists an algorithm that maps the natural numbers to the set.), we would have the algoritm $\tau$ that enumerates $T$. We would later prove that the set of all proofs is enumerable therefore by choosing $\delta = \tau$ we would have a consistent and complete deductive system.
                        \end{theorem}
                        \begin{lemma}
                            A decidable subset of an enumerable set is enumerable.
                            \proof if $f$ is the enumerating function of a set $A$. If $S\subseteq A$ is empty set. Then it is enumerable by definition. If not there exists $s\in S$ thus we enumerate the set by the following function:
                            \begin{equation}
                                g(n)=\left\{\begin{matrix}
                                    f(n) & \text{if } f(n) \in S\\
                                    s & \text{otherwise}\end{matrix}\right.
                            \end{equation}
                        \end{lemma}
                        \begin{lemma}
                            A subset $S$ of an enumerable set $X$ is decidable relative to $X$ is decidable relative to $X$ if and only if both $S$ and its complement $X\backslash S$ are enumerable.
                            \proof If $S$ is decidable, then so is $X\backslash S$, and so both $S$ and $X\backslash S$ are enumerable by Lemma 2. Conversely, suppose that both $S$ and $X\backslash S$ are enumerable. If either one is empty then, $S$ is decidable, by Lemma 1. Suppose both $S$ and its complement are nonempty sets, in which case they are enumerated by some computable functions $f$ and $g$, respectively. Then, for deciding $x$ we need only compute $f(0),g(0),f(1),g(1),\dots$ until we encounter $x$.
                        \end{lemma}
                        \begin{theorem}
                            The set of all proofs is enumerable.
                            \proof Fir any enumerable alphabet $L$ we have:
                            \begin{equation}
                                L^\infty = \left\{x | x\in L\right\} \cup \left\{xy|x,y\in L\right\}\dots
                            \end{equation}
                            Therefore we have an algorithm that goes through all the words now since the alphabet of $P$ is enumerable, then $P^\infty$ and its subsets are enumerable.
                        \end{theorem}
                        \begin{lemma}
                            Suppose that $R$ is an enumerable set and $f$ is a computable function which is defined on all elements of $R$. Then $f(R)$ is an enumerable set.
                            \proof If $R$ is empty, then so is $f(R)$ therefore enumerable by definition. If $R$ is enumerated by a function $\rho(x)$ then $f(R)$ is enumerated by $\eta(x) = f(\rho(x))$.
                        \end{lemma}
                        \begin{theorem}
                            The set of all provable words (for a deductive system) is enumerable.
                            \proof Let $Q$ be the set of all provable words for the deductive system $\left<P, \bar P, \delta\right>$  obviously $Q = \delta(\bar P)$. However $P$ is enumerable by theorem 4. Hence $Q$ is also enumerable by lemma 4.
                        \end{theorem}
                        It follows now that if $T$ is not enumerable set, then it is impossible to find a complete and consistent deductive system for the pair $\left< \curveL,T\right>$, since the set $Q$ of provable words for any consistent deductive system is a proper subset of $T$, and there will have to be an element on complement $T\backslash Q$. Such an element is a true but unprovable statement!
                        \\
                        \\
                        Theorems 3 and 5 together give a condition on a fundamental pair which is necessary and sufficient for the existence of a complete and consistent deductive system for the pair. This condition is enumerability of the set of all truths. 
                        \\
                        \\
                        One would expect that in a "rich" or "expressive" language the set of all truths is too complicated to be enumerable, and hence there are no complete and consistent deductive systems for such a language. However, the criterion in theorems 3 and 5 is not very convineint to use, since it is often difficult to study the entire set $T$. 


                \subsection{Philosophy}
                        In this section we would try to understand the incompleteness theorems out of the formal mathematical language. We would then proceed to talk about a mathematical universe.
                        \subsection{Introduction}
                            GÃ¶del's incompleteness theorems are groundbreaking outcomes in present-day logic that transformed the comprehension of mathematics and logic, and had significant implications for the philosophy of mathematics. While some philosophers have attempted to utilize these outcomes in other areas of philosophy, the validity of many such applications is often debatable.
                            \\
                            \\
                            To comprehend GÃ¶del's theorems, it is imperative to clarify crucial ideas related to them, including "formal system," "consistency," and "completeness." Essentially, a formal system signifies a collection of axioms furnished with inference rules, which enable the generation of new theorems. The axioms must be finite or at least decidable, meaning that an algorithm can determine whether a given statement is an axiom or not. If this criteria is fulfilled, the theory is known as "recursively axiomatizable," or simply "axiomatizable." The inference rules of a formal system are also effective operations that allow one to ascertain if one has made a legitimate application of a rule of inference. As a result, it is always possible to determine if any given finite sequence of formulas constitutes a real derivation in the system, given the axioms and the rules of inference.
                            \\
                            \\
                            A formal system is complete if every statement of the language of the system can be derived (proven) in the system or its negation can be proven. A formal system is consistent when there exists no statement in which the statement itself and its negation can both be derived in the system. In this context, only consistent systems are of interest since an inconsistent formal system renders every statement derivable, hence rendering such a system trivially complete.
                            \\
                            \\
                            GÃ¶del discovered two distinct yet interconnected incompleteness theorems, typically known as the first and second incompleteness theorems. Although "GÃ¶del's theorem" may refer to both in conjunction, it often refers to the first one separately. With a modification introduced by J. Barkley Rosser in 1936, the first theorem can be roughly stated as follows:
                            \begin{qt}
                                Any consistent formal system $F$ within which a certain amount of elementary arithmetic can be carried out is incomplete, meaning there are statements in the language of $F$ which can neither be proved nor disproved in $F$.
                            \end{qt}
                            GÃ¶del's theorem not only asserts the existence of such statements, but also explicitly produces a specific sentence that is neither provable nor refutable in formal system $F$ through GÃ¶del's proof method. This "undecidable" statement can be mechanically generated from a specification of $F$ and is a relatively simple statement of number theory, a purely universal arithmetical sentence.
                            \\
                            \\
                            One common misconception about GÃ¶del's first theorem is interpreting it as showing the presence of truths that cannot be proven. However, this is incorrect because the incompleteness theorem deals with derivability in a particular formal system, rather than provability in an absolute sense. For any statement $A$ unprovable in a given formal system $F$, there are other formal systems where $A$ is provable (by taking $A$ as an axiom). On the other hand, the standard axiom system of Zermelo-Fraenkel set theory (denoted as $ZF$ or $ZFC$ with the axiom of choice) is powerful enough to derive all ordinary mathematics. Nevertheless, there exist arithmetical truths that are not provable even in $ZFC$ due to GÃ¶del's first theorem. Hence, proving them would require a formal system that goes beyond $ZFC$ methods. Therefore, these truths are not provable using today's "ordinary" mathematical methods and axioms, nor can they be proved in a way that mathematicians would regard as conclusive and unproblematic.\cite{Hajek2007-fq}
                            \\
                            \\
                            GÃ¶del's second incompleteness theorem concerns the limitations of consistency proofs and can be roughly stated as:
                            \begin{qt}
                                For any consistent system $F$ within which a certain amount of elementary arithmetic can be carried out, the consistency of $F$ cannot be proved in $F$  itself.
                            \end{qt}
                            The second theorem requires a slightly more elaborate version of formal system $F$, encompassing more arithmetic than the one required for the first theorem, which holds under much weaker assumptions. It is important to note that, like the first incompleteness theorem, the second theorem pertains only to formal provability or derivability relative to some formal system (in this case, $F$ itself). It does not imply anything about whether the statement "$T$ is consistent" can be proven true by an argument considered conclusive or acceptable by mathematicians for a particular theory $T$ satisfying the conditions of the theorem. For many theories, such proof is possible.
                            
                        \subsection{Incompleteness Theorems and The Church-Turing Thesis}
                            Initially, GÃ¶del demonstrated the incompleteness of a particular but extensive formalized theory $P$, which is a variation of Russell's type-theoretical system $PM$ (Principia Mathematica). This system encompasses all extensions of $P$ with the same language whose set of axioms is primitive recursive. Although GÃ¶del did not demonstrate, he suggested that the proof could be adapted to apply to standard axiom systems of set theory such as $ZFC$. At that time, it was unclear how general the result was, despite the fact that GÃ¶del had a very general outcome.
                            \\
                            \\
                            What remained uncertain was the analysis of the intuitive notion of decidability, necessary in characterizing the concept of an arbitrary formal system. Mathematicians and logicians have employed the intuitive notion of a decision method since ancient times. For the general results such as the general incompleteness theorems or the undecidability results, however, a precise mathematical explication of the notion would be necessary. Instead of decidable sets or properties, effective or computable functions or operations are often considered, but these are two sides of the same coin.
                            \\
                            \\
                            GÃ¶del, Church, and Turing independently proposed different exact mathematical definitions of computable functions and decidable sets of numbers, which were later found to be equivalent. Turing's careful conceptual analysis that used fictional and abstract computing machines, conventionally known as "Turing machines," was significant, as emphasized by GÃ¶del himself. The intuitive notion and some of these mathematical explications are often labeled as "The Church-Turing thesis." For historical reasons, the term "recursive function" has been dominant in the logical literature, so decidable sets are often termed as "recursive sets."
                            \\
                            \\
                            To comprehend the incompleteness and undecidability results correctly, understanding the distinction between two key concepts regarding sets is crucial. First, there may be a mechanical method that decides whether any given number belongs to the set or not, in which case, the set is referred to as "decidable" or "recursive." Second, there may be a mechanical method that generates or lists the elements of the set, number by number. In the latter case, the set is referred to as "recursively enumerable" (r.e.), meaning it can be effectively generated or is "semi-decidable." A fundamental outcome of the theory of computability is that semi-decidable sets can be effectively generated but not decidable. This is essentially the essence of the first incompleteness theorem at an abstract level. However, if both a set and its complement are recursively enumerable, the set is recursive, i.e., decidable.\cite{sep-church-turing}
            \section{Nature aa a Mathematical Entity}
                The incompleteness theorem, together with the computation theorem (Church-Turing Thesis) establish a limit on mathematical abstraction. Being depended on the choice of axioms the two refer to unprovable or incomputable entities in mathematics and computations. There can be a lot to learn from these two theorems and to grasp a better understanding of the world as a whole. But there is a subtle difference between a physicists and a mathematicians. 
                \\
                \\
                The assumption that world is the realism of an abstraction is not a new one. In fact, it is as ancient as Plato! 
                \subsection{Platonism in Mathematics}
                    \subsubsection{What is Mathematical Platonism}
                        Mathematical platonism can be defined as the conjunction of the following three theses:
                        \begin{enumerate}
                            \item  \textbf{Existence: }There are mathematical objects.
                            \item  \textbf{Abstractness:} Mathematical objects are abstract.
                            \item  \textbf{Independence:} Mathematical objects are independent of intelligent agents and their language, thought, and practices.
                        \end{enumerate}
                        Platonism, not just limited to mathematics, encompasses any belief system that is based on the three aforementioned claims. The first two claims are relatively straightforward: existence can be expressed as "$\exists xMx$," where "$Mx$" represents the predicate "$x$ is a mathematical object," which refers to objects studied in pure mathematics such as numbers, sets, and functions. Abstractness asserts that all mathematical objects are non-spatiotemporal and therefore causally inefficacious. \cite{sep-platonism-mathematics}
                        \\
                        \\
                        Independence, however, is a bit more complex. It is commonly understood as the notion that even if there were no intelligent agents or if their language, thought, or practices were different, mathematical objects would still exist. However, this interpretation may be insufficient to fully capture the concept of independence At present, the concept of independence remains somewhat vague.
                    \subsubsection{Historical Remarks}
                        Platonism should be distinguished from the historical view of Plato himself. In contemporary debates about platonism, few argue for a strong exegetical interpretation of Plato's view, let alone defend it. While the term "platonism" is inspired by Plato's theory of abstract and eternal Forms, the current definition of platonism is independent of its original historical inspiration.\cite{sep-platonism-mathematics}
                        \\
                        \\
                        It's important to note that platonism is purely a metaphysical view and distinct from other views with substantive epistemological content. Past characterizations of platonism often included strong epistemological claims that implied we have an immediate insight or grasp of the realm of abstract objects. However, it is now more common to reserve the term "platonism" for the purely metaphysical view described earlier. Many philosophers who defend platonism in this sense would reject the additional epistemological claims, including Quine and those drawn to the indispensability argument, which aims to provide an empirical defense of mathematical platonism.
                        \\
                        \\
                        Lastly, the definition of "mathematical platonism" excludes the claim that all truths of pure mathematics are necessary, despite it being traditionally held by most platonists. This exclusion is justified by the fact that some philosophers considered platonists, such as Quine and advocates of the aforementioned indispensability argument, reject this additional modal claim.
                    \subsubsection{The Philosophical Significance of Mathematical Platonism}
                        Mathematical platonism has significant philosophical implications that challenge the physicalist idea that reality is limited to the physical world. According to platonism, reality extends beyond the physical and includes abstract objects that are not part of the spatiotemporal and causal order studied by the physical sciences. Additionally, if mathematical platonism is true, it would put pressure on many naturalistic theories of knowledge because we undeniably possess mathematical knowledge, which implies knowledge of causally inefficacious objects.
                        \\
                        \\
                        While these philosophical consequences are not exclusive to mathematical platonism, this form of platonism is uniquely equipped to support them due to the tremendous success of mathematics as a discipline in its own right and as a tool for other sciences. Contemporary analytic philosophers are reluctant to contradict any of the core claims of a discipline with the scientific credentials of mathematics. Rejecting mathematics outright would be unattractive if philosophical analysis were to reveal some strange and surprising consequences of the discipline. In contrast, a form of platonism based on a discipline with less impressive scientific credentials than mathematics would not be as fortunate. For example, when theology leads to unexpected philosophical consequences, many philosophers do not hesitate to reject the relevant parts of theology.
                    \subsubsection{Object Realism}
                        Object realism asserts the existence of abstract mathematical objects and is the combination of Existence and Abstractness. This view stands in contrast to nominalism, which holds that there are no abstract objects, although the term "nominalism" may refer to the belief that there are no universals in traditional philosophical usage. 
                        \\
                        \\
                        Object realism is logically weaker than mathematical platonism because it does not include Independence. Consequently, the philosophical implications of object realism are not as strong as those of platonism. Physicalists may accept non-physical objects if they are dependent on or reducible to physical objects, such as corporations, laws, and poems. Furthermore, there is no mystery about acquiring knowledge of non-physical objects that we have constituted or made.
                        \\
                        \\
                        Some views in the philosophy of mathematics align with object realism but are not platonist. Traditional intuitionist views, for example, affirm the existence of mathematical objects but maintain that these objects depend on or are constituted by mathematicians and their activities. 
                    \subsubsection{Truth-Value Realism}
                        Truth-value realism posits that every well-formed mathematical statement has a unique and objective truth-value that is independent of our ability to know it or whether it logically follows from current mathematical theories. Furthermore, this view asserts that most statements deemed to be true in mathematics are indeed true. Although this is a metaphysical view, it differs from platonism in that truth-value realism does not commit to an ontology of mathematical objects to explain the truth-values of mathematical statements.
                        \\
                        \\
                        Platonism may provide motivation for truth-value realism by explaining how mathematical statements acquire their truth-values. However, truth-value realism does not entail platonism or object realism unless additional premises are added. Nominalists, who do not believe in the existence of abstract objects, may still endorse truth-value realism, at least for basic branches of mathematics such as arithmetic. In this case, they translate mathematical statements into a language that does not rely on the existence of abstract objects.
                        \\
                        \\
                        Some philosophers suggest that the debate about platonism should be transformed into a debate about truth-value realism because it is clearer and more important to both philosophy and mathematics than the former. They argue that the debate about truth-value realism is more tractable than the debate about platonism, which is often unclear.
                    \subsubsection{The Mathematical Significance of Platonism}
                        Working realism is a methodological view that advocates for practicing mathematics as if platonism were true, according to Bernays (1935) and Shapiro (1997, pp. 21-27 and 38-44). This requires further clarification. Platonism has been used in the past to defend particular mathematical methods in debates about the foundations of mathematics, including:
                        \begin{enumerate}
                            \item Classical first-order (or stronger) languages whose singular terms and quantifiers appear to be referring to and ranging over mathematical objects. (This contrasts with the languages that dominated earlier in the history of mathematics, which relied more heavily on constructive and modal vocabulary.)
                            \item Classical rather than intuitionistic logic.
                            \item Non-constructive methods (such as non-constructive existence proofs) and non-constructive axioms (such as the Axiom of Choice).
                            \item Impredicative definitions (that is, definitions that quantify over a totality to which the object being defined would belong).
                            \item âHilbertian optimismâ, that is, the belief that every mathematical problem is in principle solvable.
                          \end{enumerate}
                        Working realism endorses classical methods, including non-constructive methods and impredicative definitions, in mathematical reasoning. However, it does not take a stance on whether these methods require philosophical defense, or if such defense must be based on platonism. Working realism is primarily a view within mathematics about the correct methodology of the discipline, whereas platonism is an explicitly philosophical view. Therefore, they are distinct views.
                        \\
                        \\
                        Mathematical platonism provides strong support for working realism. If platonism is true, then the language of mathematics should follow classical first-order logic, and non-constructive methods, impredicative definitions, and Hilbertian optimism would also be justified. Furthermore, the truth of platonism would have significant implications within mathematics, justifying the use of classical methods and motivating the search for new axioms to settle unresolved mathematical questions.
                        \\
                        \\
                        However, working realism does not necessarily imply platonism. Although it endorses the use of the platonistic language of contemporary mathematics, this falls short of platonism in two ways. Firstly, the platonistic language can be analyzed without reference to and quantification over mathematical objects. Secondly, even if face-value analysis of the language could be justified, this would only support object realism, not platonism. An additional argument would be necessary to uphold Independence, the third component of platonism.\cite{sep-platonism-mathematics}\cite{Benson2006-jm}\cite{Tegmark2008-qv}
                        

                            


                        





                        

                


                    \newpage
                    \bibliography{logicsources}
                    \bibliographystyle{plain}
            




\end{document}